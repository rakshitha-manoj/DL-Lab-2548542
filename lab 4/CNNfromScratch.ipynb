{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad1739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created subset: 100 images per class.\n",
      "Structure: 70 Train | 15 Val | 15 Test per category.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def create_subset_split(base_path, target_path, images_per_class=100):\n",
    "    classes = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]\n",
    "    \n",
    "    train_n = int(images_per_class * 0.7)\n",
    "    val_n = int(images_per_class * 0.15)\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for cls in classes:\n",
    "            os.makedirs(os.path.join(target_path, split, cls), exist_ok=True)\n",
    "\n",
    "    for cls in classes:\n",
    "        cls_path = os.path.join(base_path, cls)\n",
    "        all_images = os.listdir(cls_path)\n",
    "        \n",
    "        random.seed(42)\n",
    "        random.shuffle(all_images)\n",
    "        subset = all_images[:images_per_class]\n",
    "\n",
    "        train_imgs = subset[:train_n]\n",
    "        val_imgs = subset[train_n:train_n + val_n]\n",
    "        test_imgs = subset[train_n + val_n:]\n",
    "\n",
    "        for split_name, img_list in zip(['train', 'val', 'test'], [train_imgs, val_imgs, test_imgs]):\n",
    "            for img in img_list:\n",
    "                shutil.copy(\n",
    "                    os.path.join(cls_path, img),\n",
    "                    os.path.join(target_path, split_name, cls, img)\n",
    "                )\n",
    "                \n",
    "    print(f\"Created subset: {images_per_class} images per class.\")\n",
    "    print(f\"Structure: 70 Train | 15 Val | 15 Test per category.\")\n",
    "\n",
    "create_subset_split('data', 'satellite_subset', images_per_class=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f238451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1cfa257",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(Layer):\n",
    "    def __init__(self, input_shape, kernel_size, depth):\n",
    "      \n",
    "        self.input_shape = input_shape\n",
    "        self.input_depth, self.input_height, self.input_width = input_shape\n",
    "        self.depth = depth\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.output_shape = (depth, self.input_height - kernel_size + 1, self.input_width - kernel_size + 1)\n",
    "        \n",
    "        self.kernels = np.random.randn(depth, self.input_depth, kernel_size, kernel_size) * np.sqrt(2/self.input_depth)\n",
    "        self.biases = np.zeros(self.output_shape)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = np.copy(self.biases)\n",
    "        \n",
    "        for d in range(self.depth):\n",
    "            for i in range(self.input_depth): \n",
    "                self.output[d] += self._correlate(self.input[i], self.kernels[d, i])\n",
    "        return self.output\n",
    "\n",
    "    def _correlate(self, img, kernel):\n",
    "        h, w = img.shape\n",
    "        k = self.kernel_size\n",
    "        out_h, out_w = h - k + 1, w - k + 1\n",
    "        res = np.zeros((out_h, out_w))\n",
    "        \n",
    "        for y in range(out_h):\n",
    "            for x in range(out_w):\n",
    "                res[y, x] = np.sum(img[y:y+k, x:x+k] * kernel)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d948a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLayer(Layer):\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.maximum(0, input)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return output_gradient * (self.input > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f30c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool(Layer):\n",
    "    def __init__(self, kernel_size=2, stride=2):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.depth, self.input_height, self.input_width = input.shape\n",
    "        self.output_height = (self.input_height - self.kernel_size) // self.stride + 1\n",
    "        self.output_width = (self.input_width - self.kernel_size) // self.stride + 1\n",
    "        \n",
    "        output = np.zeros((self.depth, self.output_height, self.output_width))\n",
    "        \n",
    "        for d in range(self.depth):\n",
    "            for i in range(self.output_height):\n",
    "                for j in range(self.output_width):\n",
    "                    h_start = i * self.stride\n",
    "                    h_end = h_start + self.kernel_size\n",
    "                    w_start = j * self.stride\n",
    "                    w_end = w_start + self.kernel_size\n",
    "                    \n",
    "                    output[d, i, j] = np.max(input[d, h_start:h_end, w_start:w_end])\n",
    "        return output\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        d_input = np.zeros(self.input.shape)\n",
    "        \n",
    "        for d in range(self.depth):\n",
    "            for i in range(self.output_height):\n",
    "                for j in range(self.output_width):\n",
    "                    h_start = i * self.stride\n",
    "                    h_end = h_start + self.kernel_size\n",
    "                    w_start = j * self.stride\n",
    "                    w_end = w_start + self.kernel_size\n",
    "                    \n",
    "                    window = self.input[d, h_start:h_end, w_start:w_end]\n",
    "                    mask = (window == np.max(window))\n",
    "                    \n",
    "                    d_input[d, h_start:h_end, w_start:w_end] += mask * output_gradient[d, i, j]\n",
    "        return d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "056e612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(Layer):\n",
    "    def forward(self, input):\n",
    "        self.input_shape = input.shape\n",
    "        return input.flatten().reshape(1, -1) \n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return output_gradient.reshape(self.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "623ebf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size) * np.sqrt(1/input_size)\n",
    "        self.biases = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.dot(input, self.weights) + self.biases\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        weights_gradient = np.dot(self.input.T, output_gradient)\n",
    "        input_gradient = np.dot(output_gradient, self.weights.T)\n",
    "\n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.biases -= learning_rate * output_gradient\n",
    "        \n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d8562fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Layer):\n",
    "    def forward(self, input):\n",
    "        exps = np.exp(input - np.max(input))\n",
    "        self.output = exps / np.sum(exps)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return output_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b3b86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_cross_entropy(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    return -np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "def categorical_cross_entropy_gradient(y_true, y_pred):\n",
    "    return y_pred - y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76c56b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteCNN:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def predict(self, input):\n",
    "        output = input\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "\n",
    "    def train(self, x_train, y_train, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for x, y in zip(x_train, y_train):\n",
    "                output = self.predict(x)\n",
    "                \n",
    "                total_loss += categorical_cross_entropy(y, output)\n",
    "                \n",
    "                gradient = categorical_cross_entropy_gradient(y, output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    gradient = layer.backward(gradient, learning_rate)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(x_train):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e2bc5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SatelliteCNN([\n",
    "    ConvLayer((3, 32, 32), kernel_size=3, depth=8), \n",
    "    ActivationLayer(),\n",
    "    MaxPool(kernel_size=2, stride=2),               \n",
    "    Flatten(),                                      \n",
    "    Dense(1800, 4),                                 \n",
    "    Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf98892c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
